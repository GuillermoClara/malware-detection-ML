import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb

import sklearn.model_selection as md
from sklearn.metrics import accuracy_score

from sklearn.neighbors import KNeighborsClassifier

from sklearn.ensemble import RandomForestClassifier

from sklearn.linear_model import LogisticRegression

import random

import warnings


def knn_analyzer(dataset, proportion=0.75):
    """
       Analyzer used to see how accuracy changes using different parameters for KNN models. \n
       Takes into account the type of distance metric used and the amount of neighbors
       :param dataset: pandas Dataframe
       :param proportion: (% from 0 to 1) of dataset used for training
    """

    print('Generating chart, dont stop the program...')

    comparison_df = pd.DataFrame(columns=['k', 'accuracy', 'distance'])

    predictors = dataset.drop('type', axis=1)
    target = dataset['type']

    train_x, test_x, train_y, test_y = md.train_test_split(predictors,
                                                           target,
                                                           random_state=42,
                                                           train_size=proportion,
                                                           test_size=(1 - proportion))

    for i in range(2, 53, 2):

        classifier = KNeighborsClassifier(n_neighbors=i, p=1)
        classifier2 = KNeighborsClassifier(n_neighbors=i, p=2)

        classifier.fit(train_x, train_y)
        classifier2.fit(train_x, train_y)

        prediction = classifier.predict(test_x)
        prediction2 = classifier2.predict(test_x)

        accuracy = accuracy_score(test_y, prediction)
        accuracy2 = accuracy_score(test_y, prediction2)

        with warnings.catch_warnings():
            warnings.simplefilter('ignore')
            comparison_df = comparison_df.append({'k': i, 'accuracy': accuracy, 'distance': 'Manhattan'}, ignore_index=True)
            comparison_df = comparison_df.append({'k': i, 'accuracy': accuracy2, 'distance': 'Euclidean'},
                                             ignore_index=True)

    sb.lineplot(x="k",
                y="accuracy",
                hue="distance",
                data=comparison_df)

    plt.title('Accuracy vs K per Distance measure')

    plt.savefig('./charts/KNN_Analysis.png')

    print('Most optimal parameters: ')
    print(comparison_df.sort_values(by='accuracy', ascending=False).head(1))
    print('You can see the generated chart after stopping the simulation')


def random_forest_analyzer(dataset, proportion=0.75):
    """
           Analyzer used to see how accuracy changes using different parameters for Random Forest models. \n
           Takes into account the type of criterion and number of estimators used
           :param dataset: pandas Dataframe
           :param proportion: (% from 0 to 1) of dataset used for training
        """

    print('Generating chart, dont stop the program...')

    comparison_df = pd.DataFrame(columns=['n_estimators', 'accuracy', 'max_depth'])

    predictors = dataset.drop('type', axis=1)
    target = dataset['type']
    train_x, test_x, train_y, test_y = md.train_test_split(predictors,
                                                           target,
                                                           random_state=42,
                                                           train_size=proportion,
                                                           test_size=(1 - proportion))

    for i in range(100, 1001, 100):

        classifier = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=5)
        classifier2 = RandomForestClassifier(n_estimators=i, criterion='entropy', max_depth=5)

        classifier.fit(train_x, train_y)
        classifier2.fit(train_x, train_y)

        prediction = classifier.predict(test_x)
        prediction2 = classifier2.predict(test_x)

        accuracy = accuracy_score(test_y, prediction)
        accuracy2 = accuracy_score(test_y, prediction2)

        with warnings.catch_warnings():
            warnings.simplefilter('ignore')
            comparison_df = comparison_df.append({'n_estimators': i, 'accuracy': accuracy, 'criterion': 'gini'},
                                             ignore_index=True)

            comparison_df = comparison_df.append({'n_estimators': i, 'accuracy': accuracy2, 'criterion': 'entropy'},
                                             ignore_index=True)

    print('Most optimal parameters: ')
    print(comparison_df.sort_values(by='accuracy', ascending=False).head(1))

    sb.lineplot(x="n_estimators",
                y="accuracy",
                hue="criterion",
                data=comparison_df)

    plt.title('Accuracy vs n_estimators per criterion')

    plt.savefig('./charts/RandomForestAnalysis.png')

    print('Chart generation finished!')
    print('You can see the generated chart after stopping the simulation')


def logistic_regression_analyzer(dataset, proportion=0.75):
    """
    Analyzer for Centralized Logistic Regression

    :param dataset: pandas Dataframe
    :param proportion: (% from 0 to 1) of dataset used for training

    """

    print('Generating table, dont stop the program...')

    predictors = dataset.drop('type', axis=1)
    target = dataset['type']
    train_x, test_x, train_y, test_y = md.train_test_split(predictors,
                                                           target,
                                                           random_state=42,
                                                           train_size=proportion,
                                                           test_size=(1 - proportion))

    rows = []

    for penalty, solver in zip(['l1', 'l2'], ['liblinear', 'lbfgs']):

        print(penalty,solver)

        if penalty != 'elasticnet':
            logistic = LogisticRegression(penalty=penalty, solver=solver, random_state=42, max_iter=100)
        else:
            l1_ratio = 0.5
            logistic = LogisticRegression(penalty=penalty, solver=solver, random_state=42, max_iter=100,
                                          l1_ratio=l1_ratio)

        logistic.fit(train_x, train_y)

        prediction = logistic.predict(test_x)

        rows.append({'penalty': penalty, 'accuracy': accuracy_score(test_y, prediction)})

    comparison_df = pd.DataFrame.from_dict(rows)
    print(comparison_df)


def federated_learning_visualizer(devices):
    """
    Analyzer for metric progress overtime for edge devices in federated learning
    :param devices: devices used during federated process
    """

    print('Generating chart, dont stop the program...')

    rows = []

    for device in devices:

        dicts = device.metrics_per_iteration
        for dictionary in dicts:
            dictionary['device_id'] = device.id

        rows.extend(dicts)

    federated_df = pd.DataFrame.from_dict(rows)

    sb.lineplot(x="iteration",
                y="accuracy",
                data=federated_df, label='Accuracy')

    sb.lineplot(x="iteration",
                y="recall",
                data=federated_df, label='Recall')

    sb.lineplot(x="iteration",
                y="precision",
                data=federated_df, label='Precision')

    plt.title('Metrics of edge devices models over iterations')

    random_img_number = random.randint(0, 150230)
    filename = "Federated_Analysis"+str(random_img_number)+'.png'

    plt.savefig('./charts/'+filename)

    print('Chart generation finished!')
    print('You can see the generated chart after stopping the simulation with the name '+filename)


def federated_individual_analyzer(edge_device):
    """
    Analyzer for metric progress for a specific edge device during federated process
    :param edge_device: EdgeDevice object
    :return:
    """

    print('Generating chart, dont stop the program...')

    federated_df = pd.DataFrame.from_dict(edge_device.metrics_per_iteration)

    sb.lineplot(x="iteration",
                y="accuracy",
                data=federated_df, label='Accuracy')

    sb.lineplot(x="iteration",
                y="recall",
                data=federated_df, label='Recall')

    sb.lineplot(x="iteration",
                y="precision",
                data=federated_df, label='Precision')

    plt.title('Metrics of Edge Device #'+str(edge_device.id)+' over iterations')

    filename = "Federated_Analysis" + str(edge_device.id) + '.png'

    plt.savefig('./charts/'+filename)

    print('Chart generation finished!')
    print('You can see the generated chart after stopping the simulation with the name ' + filename)


def analyzer_parsed_files(files, model_preference):
    print('Generating chart, dont stop the program...')

    files_df = pd.DataFrame.from_dict(files)

    sb.countplot(data=files_df, x='type', hue='classified')
    plt.title('Using '+model_preference)

    random_img_number = random.randint(0, 150230)
    filename = 'parsed_files'+str(random_img_number)+'.png'

    plt.savefig('./charts/'+filename)

    print('Chart generation finished!')
    print('You can see the generated chart after stopping the simulation with the name ' + filename)